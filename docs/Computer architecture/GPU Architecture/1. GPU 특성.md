---
layout: default
title: "1. GPU 특성"
parent: "GPU Architecture"
nav_order: 2
---

# 1. GPU 특성
---
## 1. Design: GPU vs. CPU

---
GPU는 원래 그래픽 렌더링을 위해 설계되었다. 3D 객체를 구성하는 수천 개의 독립적인 폴리곤을 셰이딩, 텍스처링, 렌더링하는 데 매우 효과적이다.

![CPU vs GPU](/images/ArchCPUGPUcores.png)
- **Core (녹색 영역)** : 명령어 실행 및 계산 처리 (연산, 레지스터 조작 등)
- **Control (금색 영역)** : 명령어 해석 및 실행 제어 (제어 신호 생성, 흐름 제어 등)
- **L1 Cache (보라 영역)** : 데이터 / 명령어 저장 (코어에 가장 가까운 고속 캐시 메모리)
- **L2/L3 chache (파랑 영역)** : L1 보다 느리지만 더 큼. L3는 여러 코어 간 공유되는 경우가 많음

>
☑️ 위 그림으로 알수 있는 점
1. CPU는 GPU만큼 산술 논리 장치나 부동 소수점 장치가 많지 않다. (Core 녹색 영역)
   - 하지만 CPU 코어의 ALU와 FPU는 더 많은 기능을 갖추고 있다.
2. CPU는 GPU보다 캐시 메모리가 더 많다.
3. GPU는 병렬화 될 수 있는 워크로드를 위해 설계되었다.
   - core의 각 행마다 Control이 하나씩 있는 것으로 나타난다.

<br>

| 특징 | CPU | GPU |
|---|---|---|
| **목적** | 범용 컴퓨팅 (다양한 작업 처리)| 병렬 컴퓨팅 (그래픽 및 대량 데이터 처리)|
| **코어 수**| 적음 (일반적으로 2~64개) | 매우 많음 (수백 ~ 수천 개의 코어) |
| **작업 유형**| 직렬 처리에 최적화 | 병렬 처리에 최적화|
| **사용 사례**| 운영체제, 일반 소프트웨어, 논리 연산| 그래픽 렌더링, 머신러닝, 과학 계산 |

<br>

## 2. Performance: GPU vs. CPU
---
아래의 그림은 연산 능력을 초당 수십억 번의 부동 소수점 연산( Gflop/s )으로 측정하여 보여준다.

<!-- ![peakFlops](/images/PeakFlopsCPUGPU.png) -->
<center><img src="/images/PeakFlopsCPUGPU.png" width="80%" height="80%"></center>

- Single Precision (단정밀도) : 부동 소수점 수의 32비트 표현
- Double Percision (배정밀도) : 부동 소수점 수의 64비트 표현

단정밀도는 배정밀도보다 두 배 빠르게 처리될 수 있는 경우가 많다.

<br>

## 3. Threads, Cores 재정의
---
GPU는 그래픽 파이프라인의 두 가지 핵심 속성을 통해 속도가 가속화된다.

1. 렌더링은 일반적으로 많은 독립적인 오브젝트 (예:표면을 근사화하는 작은 삼각형 메시)로 구성된다.
2. 각 오브젝트를 렌더링하는데 필요한 단계의 순서는 기본적으로 모든 오브젝트에 동일하다.
    - 따라서 계산 단계가 모든 오브젝트에 대해 한번번에 병렬로 수행될 수 있다.

**GPU와 CPU 간의 용어 비교**

|GPU 용어| GPU에서의 간단한 정의 | CPU에서의 대응 개념 |
|---|---|---|
| **Thread** | 하나의 CUDA 코어에서 실행되는 명령어와 데이터의 흐름. `SIMT 모델`에서 실행됨. | 일반적으로 명시적 대응 없음. |
| **CUDA Core**| SIMT 명령어의 일부를 처리하는 단일 연산 유닛.  | 벡터 유닛 내의 벡터 레인   |
| **Warp**| 32개의 스레드로 구성된 그룹. 서로 다른 데이터에 동일한 `명령어 스트림`을 함께 실행한다.| 벡터 연산에서의 벡터 |
| **Kernel** | GPU에서 실행되는 함수. 커널은 여러 `스레드 블록`으로 구성될 수 있다.| CPU의 스레드 |
| **Streaming Multiprocessor (SM)** | 스레드 블록을 실행할 수 있는 단위. GPU의 물리적 유닛.| CPU의 코어|
  
### ❓ 스레드 블록
- 스레드 블록 (Thread Block)
  - **여러 스레드가 모여 하나의 논리적 단위로 구성되는 실행 단위**
- CUDA 프로그래밍에서 스레드는 블록 단위로 묶여 실행된다.
- 하나의 블록은 n ~ n백개의 스레드를 포함할 수 있다.
- **블록은 SM(Streaming Multiprocessor)에 배정**된다.

### ❓ 명령어 스트림
- 명령어 스트림 (Instruction Stream)
   - 스레드들이 공유하는 명령어의 흐름 (제어 흐름 분기(`조건문`)가 영향을 줌)
- 스트림(stream)이라는 말은 일련의 명령어가 순차적으로 흐르는 데이터 흐름을 의미
- SIMT 모델에서 말하는 "명령어 스트림"은 **모든 스레드가 따르는 동일한 명령어 흐름**

<br>

## 4. SIMT (Single Instruction, Multiple Threads)
---
- 한 명령어를 여러 스레드가 동시에 실행하는 GPU 실행 모델

```c++
__global__ void add(int *a, int *b, int *c) {
    int idx = threadIdx.x;
    c[idx] = a[idx] + b[idx];
}
```
- 위 함수가 32개의 스레드에서 실행되면 모든 스레드가 같은 `c[idx] = a[idx] + b[idx]` 명령어 수행.
- 각 스레드는 자신만의 `idx` 값을 사용해서 다른 데이터에 접근함.

### SIMT에서 제어 흐름 분기 예시

- SIMT에서는 **선택한 스레드를 활성화 또는 비활성화할 수 있다**

![SIMT 제어 흐름 분기](/images/simtVolta.png)

>
- 활성 스레드: 명령과 데이터 처리.
- 비활성 스레드: 아무런 작업도 수행하지 않음. 로컬 데이터가 변경되지 않은 상태로 유지됨.

## 5. Warps
---
>
- 런타임 시, 스레드 블록은 SIMT 실행을 위해 워프로 나뉜다.
- 하나의 완전한 워프는 연속된 스레드 인덱스를 가진 32개의 스레드 묶음으로 구성된다.
- 워프에 포함된 스레드들은 32개의 CUDA 코어 집합에 의해 함께 처리된다.

<br>

## 6. Kernels (in software)
---
연결된 GPU 에서 병렬로 실행되도록 설계된 함수를 커널이라고 한다.
>
- C++ 함수 선언 앞에 `__global__` 지정자가 있는 것으로 식별된다.

- 커널은 한 번만 실행되는 것이 아니라, **GPU의 N개의 서로 다른 스레드 에 의해 N번 병렬로 실행된다.**
- 각 스레드에는 메모리 주소를 계산하고 제어 결정을 내리는 데 사용할 수 있는 고유 ID(실제로는 인덱스)가 할당된다.

**CUDA 커널이 스레드 배열에 의해 실행되는 방식**

<img src="/images/kernelThreads.png" width="70%" height="70%">


>
커널 호출은 GPU에서 사용할 스레드 수를 지정하는 특수 인수를 제공해야 한다.
>
> 특수 인수는 아래와 같다. `func<<<1, N>>>(x, y, z)`

```c++

// 커널 함수 정의: 두 벡터를 더해서 결과 저장
__global__ void addVectors(int *a, int *b, int *c, int N) {
    int idx = threadIdx.x;
    if (idx < N) {
        c[idx] = a[idx] + b[idx];
    }
}

int main() {
    const int N = 256;

    // 커널 호출: 블록 1개, 스레드 256개로 구성
    addVectors<<<1, N>>>(d_a, d_b, d_c, N);
}
```

## 7. Streaming multiprocessors (in hardware)
---
GPU에서 **커널 호출은 하나 이상의 스트리밍 멀티프로세서에 의해 실행**된다.

각 SM의 CUDA 코어는 항상 32개 세트로 배열되어 SM이 스레드의 전체 워프를 실행하는 데 사용할 수 있다.

>
- GPU가 커널 호출을 실행하는 데 실제로 사용하는 SM의 수는 호출에 지정된 스레드 블록 수로 제한된다.
  - 예를 들어 `fun<<<M, N>>>(x, y, z)` 이 있을 때, 각 SM에 할당할 수 있는 블록은 최대 M개이다.
    - 스레드 블록은 여러 SM으로 분할될 수 없다. 
    - 사용 가능한 SM보다 블록이 많은 경우, 동일한 SM에 여러 블록을 할당할 수 있다.
- 매 사이클 마다 각 SM의 스케줄러 는 사용 가능한 32개의 CUDA 코어 세트에서 실행될 스레드의 전체 워프를 할당한다.
- SM에는 레지스터 , L1 캐시 , 상수 캐시, 공유 메모리가 포함된다.


## ☑️ 정리
```markdown
              [Kernel]
                 ↓
    [Grid] (커널의 전체 작업 공간 = 스레드 블록 집합)
    ┌─────────────────┐
    │ Thread Block 1                                            │ → SM 0 (리소스 여유 있을 시 SM 1에도 할당 가능)
    │ Thread Block 2                                            │ → SM 0 or 다른 SM
    │     ...                                                                   │ (한 SM이 여러 블록을 동시에 실행 가능)
    │ Thread Block N                                           │ → SM m (m ≤ n, SM 수 ≤ 블록 수)
    └─────────────────┘
          ↓             ↓
      [Warp 0]     [Warp 1] ... (각 32스레드)
          ↓             ↓
      CUDA Cores (SIMT 방식으로 워프 단위 병렬 처리 실행)
                  ↓
           ALU/FPU/Tensor Cores (실제 연산)

```

- 하나의 **커널(GPU 함수)은 수많은 스레드 블록으로 구성**
- 각 **스레드 블록은 SM에 할당되어 실행**된다.
  -  `SM이 스레드 블록을 실행한다` = SM은 워프 스케줄링, 메모리, 명령어 분배 등 `전체 실행을 관리한다`
  -  한 SM이 여러 블록을 동시에 실행 가능 (SM의 자원이 충분하다면 여러 블록을 동시에 수용 가능)
- 스레드 블록 내부의 스레드들은 **32개 단위로 워프로 나뉨**
- 각 스레드는 **CUDA 코어에서 개별적으로 연산을 수행**한다.
  - `CUDA Core가 연산을 수행한다` = 각 스레드의 연산은 CUDA 코어에서 처리된다. `각 스레드의 명령은 워프 단위로 동기화(SIMT)`되어 CUDA Core에 할당되며, 워프 내 스레드의 명령어를 `ALU/FPU에 전달해 연산을 수행`한다.
  - CUDA Core 자체가 ALU나 FPU를 내장하고 있거나, 복합적으로 연결되어 있다.
- Tensor Core는 행렬 곱 연산(Matrix Multiply) 등에 최적화된 특수 연산 유닛으로, 워프 단위에서만 활성화되며 CUDA Core와 독립적으로 존재
  
| 구성 요소|설명 |예시 용어|
|---|---|---|
| **Kernel**| GPU에서 실행되는 함 | `myKernel<<<grid, block>>>(...)`|
| **Grid**| 모든 스레드 블록의 집합|논리적 실행 단위|
| **Thread Block**| 스레드의 집합, SM에 할당됨| `blockDim.x`, `blockIdx.x` 등으로 접근 |
| **SM**| Streaming Multiprocessor. 블록을 실행하는 하드웨어 유닛| Warp Scheduler, CUDA Cores 포함|
| **Warp**| 32개 스레드로 구성된 실행 단위|SIMT 방식 실행 |
| **CUDA Core**| 실제 산술/논리 연산을 수행하는 유닛| ALU/FPU로 구성된 연산 유닛의 논리적 집합|
| **Tensor Core**| 고속 행렬 곱셈 (AI 특화) | SM 내부에 있는 별도 유닛으로 워프 단위 처리|

**FPU vs ALU vs Tensor Core**

유닛|연산 타입|주요 용도|예시
---|---|---|---|
**FPU**|부동소수점 (실수)|	물리 시뮬레이션, 3D 렌더링	|float x = y * 1.5;|
**ALU**|정수/논리 연산|인덱스 계산, 조건문|int i = j + 1;|
**Tensor Core**|행렬 연산|AI 학습/추론, DLSS|A = B × C (행렬 곱셈)|
