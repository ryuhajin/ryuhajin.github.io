---
layout: default
title: "1. GPU 특성"
parent: "GPU Architecture"
nav_order: 2
---

# 1. GPU 특성
---
## 1. Design: GPU vs. CPU

---
GPU는 원래 그래픽 렌더링을 위해 설계되었다. 3D 객체를 구성하는 수천 개의 독립적인 폴리곤을 셰이딩, 텍스처링, 렌더링하는 데 매우 효과적이다.

![CPU vs GPU](../../../images/ArchCPUGPUcores.png)
- **Core (녹색 영역)** : 명령어 실행 및 계산 처리 (연산, 레지스터 조작 등)
- **Control (금색 영역)** : 명령어 해석 및 실행 제어 (제어 신호 생성, 흐름 제어 등)
- **L1 Cache (보라 영역)** : 데이터 / 명령어 저장 (코어에 가장 가까운 고속 캐시 메모리)
- **L2/L3 chache (파랑 영역)** : L1 보다 느리지만 더 큼. L3는 여러 코어 간 공유되는 경우가 많음

>
☑️ 위 그림으로 알수 있는 점
1. CPU는 GPU만큼 산술 논리 장치나 부동 소수점 장치가 많지 않다. (Core 녹색 영역)
   - 하지만 CPU 코어의 ALU와 FPU는 더 많은 기능을 갖추고 있다.
2. CPU는 GPU보다 캐시 메모리가 더 많다.
3. GPU는 병렬화 될 수 있는 워크로드를 위해 설계되었다.
   - core의 각 행마다 Control이 하나씩 있는 것으로 나타난다.

<br>

| 특징 | CPU | GPU |
|---|---|---|
| **목적** | 범용 컴퓨팅 (다양한 작업 처리)| 병렬 컴퓨팅 (그래픽 및 대량 데이터 처리)|
| **코어 수**| 적음 (일반적으로 2~64개) | 매우 많음 (수백 ~ 수천 개의 코어) |
| **작업 유형**| 직렬 처리에 최적화 | 병렬 처리에 최적화|
| **사용 사례**| 운영체제, 일반 소프트웨어, 논리 연산| 그래픽 렌더링, 머신러닝, 과학 계산 |

<br>

## 2. Performance: GPU vs. CPU
---
아래의 그림은 연산 능력을 초당 수십억 번의 부동 소수점 연산( Gflop/s )으로 측정하여 보여준다.

<!-- ![peakFlops](../../../images/PeakFlopsCPUGPU.png) -->
<center><img src="../../../images/PeakFlopsCPUGPU.png" width="80%" height="80%"></center>

- Single Precision (단정밀도) : 부동 소수점 수의 32비트 표현
- Double Percision (배정밀도) : 부동 소수점 수의 64비트 표현

단정밀도는 배정밀도보다 두 배 빠르게 처리될 수 있는 경우가 많다.

<br>

## 3. Threads, Cores 재정의
---
GPU는 그래픽 파이프라인의 두 가지 핵심 속성을 통해 속도가 가속화된다.

1. 렌더링은 일반적으로 많은 독립적인 오브젝트 (예:표면을 근사화하는 작은 삼각형 메시)로 구성된다.
2. 각 오브젝트를 렌더링하는데 필요한 단계의 순서는 기본적으로 모든 오브젝트에 동일하다.
    - 따라서 계산 단계가 모든 오브젝트에 대해 한번번에 병렬로 수행될 수 있다.

**GPU와 CPU 간의 용어 비교**

|GPU 용어| GPU에서의 간단한 정의 | CPU에서의 대응 개념 |
|---|---|---|
| **Thread** | 하나의 CUDA 코어에서 실행되는 명령어와 데이터의 흐름. `SIMT 모델`에서 실행됨. | 일반적으로 명시적 대응 없음. |
| **CUDA Core**| SIMT 명령어의 일부를 처리하는 단일 연산 유닛.  | 벡터 유닛 내의 벡터 레인   |
| **Warp**| 32개의 스레드로 구성된 그룹. 서로 다른 데이터에 동일한 `명령어 스트림`을 함께 실행한다.| 벡터 연산에서의 벡터 |
| **Kernel** | GPU에서 실행되는 함수. 커널은 여러 `스레드 블록`으로 구성될 수 있다.| CPU의 스레드 |
| **Streaming Multiprocessor (SM)** | 스레드 블록을 실행할 수 있는 단위. GPU의 물리적 유닛.| CPU의 코어|
  
### ❓ 스레드 블록
- 스레드 블록 (Thread Block)
  - **여러 스레드가 모여 하나의 논리적 단위로 구성되는 실행 단위**
- CUDA 프로그래밍에서 스레드는 블록 단위로 묶여 실행된다.
- 하나의 블록은 n ~ n백개의 스레드를 포함할 수 있다.
- **블록은 SM(Streaming Multiprocessor)에 배정**된다.

### ❓ 명령어 스트림
- 명령어 스트림 (Instruction Stream)
   - 스레드들이 공유하는 명령어의 흐름 (제어 흐름 분기(`조건문`)가 영향을 줌)
- 스트림(stream)이라는 말은 일련의 명령어가 순차적으로 흐르는 데이터 흐름을 의미
- SIMT 모델에서 말하는 "명령어 스트림"은 **모든 스레드가 따르는 동일한 명령어 흐름**

<br>

## 4. SIMT (Single Instruction, Multiple Threads)
---
- 한 명령어를 여러 스레드가 동시에 실행하는 GPU 실행 모델

```c++
__global__ void add(int *a, int *b, int *c) {
    int idx = threadIdx.x;
    c[idx] = a[idx] + b[idx];
}
```
- 위 함수가 32개의 스레드에서 실행되면 모든 스레드가 같은 `c[idx] = a[idx] + b[idx]` 명령어 수행.
- 각 스레드는 자신만의 `idx` 값을 사용해서 다른 데이터에 접근함.

### SIMT에서 제어 흐름 분기 예시

- SIMT에서는 **선택한 스레드를 활성화 또는 비활성화할 수 있다**

![SIMT 제어 흐름 분기](../../../images/simtVolta.png)

>
- 활성 스레드: 명령과 데이터 처리.
- 비활성 스레드: 아무런 작업도 수행하지 않음. 로컬 데이터가 변경되지 않은 상태로 유지됨.

## 5. Warps
---
>
- 런타임 시, 스레드 블록은 SIMT 실행을 위해 워프로 나뉜다.
- 하나의 완전한 워프는 연속된 스레드 인덱스를 가진 32개의 스레드 묶음으로 구성된다.
- 워프에 포함된 스레드들은 32개의 CUDA 코어 집합에 의해 함께 처리된다.

<br>

## 6. Kernels (in software)
---
연결된 GPU 에서 병렬로 실행되도록 설계된 함수를 커널이라고 한다.
>
- C++ 함수 선언 앞에 `__global__` 지정자가 있는 것으로 식별된다.

- 커널은 한 번만 실행되는 것이 아니라, **GPU의 N개의 서로 다른 스레드 에 의해 N번 병렬로 실행된다.**
- 각 스레드에는 메모리 주소를 계산하고 제어 결정을 내리는 데 사용할 수 있는 고유 ID(실제로는 인덱스)가 할당된다.

**CUDA 커널이 스레드 배열에 의해 실행되는 방식**

<img src="../../../images/kernelThreads.png" width="70%" height="70%">


>
커널 호출은 GPU에서 사용할 스레드 수를 지정하는 특수 인수를 제공해야 한다.
>
> 특수 인수는 아래와 같다. `func<<<1, N>>>(x, y, z)`

```c++

// 커널 함수 정의: 두 벡터를 더해서 결과 저장
__global__ void addVectors(int *a, int *b, int *c, int N) {
    int idx = threadIdx.x;
    if (idx < N) {
        c[idx] = a[idx] + b[idx];
    }
}

int main() {
    const int N = 256;

    // 커널 호출: 블록 1개, 스레드 256개로 구성
    addVectors<<<1, N>>>(d_a, d_b, d_c, N);
}
```

## 7. Streaming multiprocessors (in hardware)
---
GPU에서 **커널 호출은 하나 이상의 스트리밍 멀티프로세서에 의해 실행**된다.

각 SM의 CUDA 코어는 항상 32개 세트로 배열되어 SM이 스레드의 전체 워프를 실행하는 데 사용할 수 있다.

>
- GPU가 커널 호출을 실행하는 데 실제로 사용하는 SM의 수는 호출에 지정된 스레드 블록 수로 제한된다.
  - 예를 들어 `fun<<<M, N>>>(x, y, z)` 이 있을 때, 각 SM에 할당할 수 있는 블록은 최대 M개이다.
    - 스레드 블록은 여러 SM으로 분할될 수 없다. 
    - 사용 가능한 SM보다 블록이 많은 경우, 동일한 SM에 여러 블록을 할당할 수 있다.
- 매 사이클 마다 각 SM의 스케줄러 는 사용 가능한 32개의 CUDA 코어 세트에서 실행될 스레드의 전체 워프를 할당한다.
- SM에는 레지스터 , L1 캐시 , 상수 캐시, 공유 메모리가 포함된다.


## ☑️ 정리
```
         [Kernel]
            ↓
    ┌────────┐
    │ Thread Block 1    │ ←→ SM 1
    │ Thread Block 2    │ ←→ SM 2
    │     ...                           │
    │ Thread Block N   │ ←→ SM n
    └────────┘
       ↓       ↓
    Warp 1   Warp 2  ... (각 32개 Thread)
       ↓
    CUDA Core (Thread 실행)
```

- 하나의 **커널(GPU 함수)은 수많은 스레드 블록으로 구성**
- 각 **스레드 블록은** 하나의 **SM에 할당되어 실행**된다.
  -  `SM이 스레드 블록을 실행한다` = 스케줄링, 메모리, 명령어 분배 등 `전체 실행을 관리한다`
- 스레드 블록 내부의 스레드들은 **32개 단위로 워프로 나뉨**
- 각 스레드는 **CUDA 코어에서 개별적으로 연산을 수행**한다.
  - `CUDA Core가 연산을 수행한다` =	각 스레드의 명령을 `ALU 단위에서 실제 계산으로 처리한다`